{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "from os import listdir\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from difflib import SequenceMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# please alter the path to locate the file you downloaded\n",
    "# files used are from \"training-RiskFactors-Complete-Set1\" and \"training-RiskFactors-Complete-Set2\" folder\n",
    "trainingpath1 = 'E:/JHU/课程/datadesign/NLP/modified_tagged_files/training-RiskFactors-Complete-Set1'\n",
    "trainingpath2 = 'E:/JHU/课程/datadesign/NLP/modified_tagged_files/training-RiskFactors-Complete-Set2'\n",
    "testingpath = \"E:/JHU/课程/datadesign/NLP/modified_tagged_files/testing-RiskFactors-Complete\"\n",
    "trainingpath = [trainingpath1, trainingpath2] \n",
    "\n",
    "# collect all file names to read in later\n",
    "names_1 = [f for f in listdir(trainingpath1) if f.endswith('.xml')]\n",
    "names_2 = [f for f in listdir(trainingpath2) if f.endswith('.xml')]\n",
    "names_3 = [f for f in listdir(testingpath) if f.endswith('.xml')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_xml(path,file):\n",
    "    tree = ET.parse(path+'/'+file)\n",
    "    root = tree.getroot()\n",
    "    text = root.find('TEXT').text\n",
    "    return text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make raw input for GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty dataframe to save corpus used as input in GUI\n",
    "corpus = pd.DataFrame(columns=['PatientID','TimeID','RawText','TagCategory','Rawtag','CleanedText','AnnotatedText','Tag_doc','Real_text_tag'])\n",
    "corpus_test = pd.DataFrame(columns=['PatientID','TimeID','RawText','TagCategory','Rawtag','CleanedText','AnnotatedText','Real_text_tag','Pred_text_tag','Real_tag_doc','Pred_tag_doc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if path is a list of paths\n",
    "patientID = []\n",
    "timeID = []\n",
    "rawText = []\n",
    "tagCategories = []\n",
    "rawtag = []\n",
    "annotatedText = []\n",
    "tag_text = []\n",
    "\n",
    "for path in trainingpath:\n",
    "    corpus_eachpath = pd.DataFrame(columns=['PatientID','TimeID','RawText','TagCategory','Rawtag','CleanedText','AnnotatedText','Tag_doc','Real_text_tag'])\n",
    "    for file in os.listdir(path):\n",
    "        #read the text part of xml file\n",
    "        text = read_xml(path,file)\n",
    "        #print(text)\n",
    "\n",
    "        #save the PatientID, TimeID to the first two columns\n",
    "        patientID.append(file.split('-')[0])\n",
    "        timeID.append(file.split('-')[1].split('.')[0])\n",
    "        #save the text to the third column\n",
    "        rawText.append(text)\n",
    "\n",
    "        #read the tags part of xml file\n",
    "        tree = ET.parse(path+'/'+file)\n",
    "        root = tree.getroot()\n",
    "        tags = root.findall('TAGS') \n",
    "        #save the tags to the fourth and fifth column\n",
    "        for tag in tags: #<TAGS>\n",
    "        \n",
    "            tagcategory_eachfile = []\n",
    "            rawtag_attrib_eachfile =[]\n",
    "            tag_text_eachfile = []\n",
    "\n",
    "            for child in tag:\n",
    "                #print(child.tag)\n",
    "                if child.tag != 'PHI':\n",
    "                    tagcategory_eachfile.append(child.tag) #save the tag category of each file to the a list\n",
    "                    for subchild in child:\n",
    "                        #combine the subchild tag  and subchild attrib to a string\n",
    "                        subchild_attrib = subchild.tag + ' ' + str(subchild.attrib)\n",
    "                        #print(subchild_attrib)\n",
    "                        rawtag_attrib_eachfile.append(subchild_attrib)\n",
    "                    \n",
    "                        if subchild.attrib.keys().__contains__('text'):\n",
    "                            subchild_text = subchild.attrib['text']\n",
    "                            subchild_text = subchild_text.strip()#remove the blank space in the text\n",
    "                            #print(subchild_text)\n",
    "                            subchild_tag = subchild.tag\n",
    "        \n",
    "                            tag_text_eachfile.append((subchild_text,subchild_tag))\n",
    "\n",
    "        \n",
    "            tagCategories.append(tagcategory_eachfile)           \n",
    "            rawtag.append(rawtag_attrib_eachfile)\n",
    "            annotatedText.append(tag_text_eachfile)\n",
    "\n",
    "    corpus_eachpath['PatientID'] = patientID\n",
    "    corpus_eachpath['TimeID'] = timeID\n",
    "    corpus_eachpath['RawText'] = rawText\n",
    "    #corpus_eachpath['TagCategory'] = tagCategories\n",
    "    corpus_eachpath['Rawtag'] = rawtag\n",
    "    #corpus_eachpath['AnnotatedText'] = annotatedText\n",
    "    #print(corpus)\n",
    "    \n",
    "    corpus = pd.concat([corpus_eachpath],axis=0)\n",
    "\n",
    "'''\n",
    "#convert the list in the column 'Rawtag_text' to string and between each element in the list, add a enter\n",
    "for index,entry in enumerate(corpus['Rawtag_text']):\n",
    "    corpus['Rawtag_text'][index] = '//'.join(entry)\n",
    "'''\n",
    "print(corpus['Rawtag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patientID = []\n",
    "timeID = []\n",
    "rawText = []\n",
    "tagCategories = []\n",
    "rawtag = []\n",
    "annotatedText = []\n",
    "tag_text = []\n",
    "\n",
    "\n",
    "for file in os.listdir(testingpath):\n",
    "    #read the text part of xml file\n",
    "    text = read_xml(testingpath,file)\n",
    "    #print(text)\n",
    "\n",
    "    #save the PatientID, TimeID to the first two columns\n",
    "    patientID.append(file.split('-')[0])\n",
    "    timeID.append(file.split('-')[1].split('.')[0])\n",
    "    #save the text to the third column\n",
    "    rawText.append(text)\n",
    "\n",
    "    #read the tags part of xml file\n",
    "    tree = ET.parse(testingpath+'/'+file)\n",
    "    root = tree.getroot()\n",
    "    tags = root.findall('TAGS') \n",
    "    #save the tags to the fourth and fifth column\n",
    "    for tag in tags: #<TAGS>\n",
    "        \n",
    "        tagcategory_eachfile = []\n",
    "        rawtag_attrib_eachfile =[]\n",
    "        tag_text_eachfile = []\n",
    "\n",
    "        for child in tag:\n",
    "            #print(child.tag)\n",
    "            if child.tag != 'PHI':\n",
    "                tagcategory_eachfile.append(child.tag) #save the tag category of each file to the a list\n",
    "                for subchild in child:\n",
    "                    #combine the subchild tag  and subchild attrib to a string\n",
    "                    subchild_attrib = subchild.tag + ' ' + str(subchild.attrib)\n",
    "                    #print(subchild_attrib)\n",
    "                    rawtag_attrib_eachfile.append(subchild_attrib)\n",
    "                    \n",
    "                    if subchild.attrib.keys().__contains__('text'):\n",
    "                        subchild_text = subchild.attrib['text']\n",
    "                        subchild_text = subchild_text.strip()#remove the blank space in the text\n",
    "                        #print(subchild_text)\n",
    "                        subchild_tag = subchild.tag\n",
    "        \n",
    "                        tag_text_eachfile.append((subchild_text,subchild_tag))\n",
    "\n",
    "        \n",
    "        tagCategories.append(tagcategory_eachfile)           \n",
    "        rawtag.append(rawtag_attrib_eachfile)\n",
    "        annotatedText.append(tag_text_eachfile)\n",
    "\n",
    "corpus_test['PatientID'] = patientID\n",
    "corpus_test['TimeID'] = timeID\n",
    "corpus_test['RawText'] = rawText\n",
    "#corpus_test['TagCategory'] = tagCategories\n",
    "corpus_test['Rawtag'] = rawtag\n",
    "#corpus_test['AnnotatedText'] = annotatedText\n",
    "#print(corpus)\n",
    "\n",
    "'''\n",
    "#convert the list in the column 'Rawtag_text' to string and between each element in the list, add a enter\n",
    "for index,entry in enumerate(corpus['Rawtag_text']):\n",
    "    corpus['Rawtag_text'][index] = '//'.join(entry)\n",
    "'''\n",
    "print(corpus_test['RawText'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make input for machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# an empty dataframe for machine learning input\n",
    "all1_df = pd.DataFrame(np.zeros((len(names_1), 3), dtype=object), columns=['text', 'annotation','loc'])\n",
    "all2_df = pd.DataFrame(np.zeros((len(names_2), 3), dtype=object), columns=['text', 'annotation','loc'])\n",
    "test_df = pd.DataFrame(np.zeros((len(names_3), 3), dtype=object), columns=['text', 'annotation','loc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_df(names,df, file_path,PHI_status = True, type = 'train'):\n",
    "    # Get text and reformat it\n",
    "    n = 0\n",
    "    for name in names:\n",
    "        tree = ET.parse(file_path +'/'+ name)\n",
    "        root = tree.getroot()\n",
    "        nt = re.sub('\\n',' ',root[0].text)\n",
    "        nt = re.sub('\\t',' ',nt) \n",
    "        nt = re.sub('\"',\"'\",nt)\n",
    "        ## sample 214 has a weird character\n",
    "        nt = re.sub('>','&gt;',nt) \n",
    "        nt = re.sub('<','&lt;',nt)\n",
    "        ## new wired character\n",
    "        nt = re.sub('Â','',nt)\n",
    "        nt = re.sub('â','',nt)\n",
    "        nt = re.sub('€','',nt)\n",
    "        nt = re.sub('™','',nt)\n",
    "        df['text'][n] = nt\n",
    "        n+=1\n",
    "    \n",
    "    # Get annotations\n",
    "    n = 0\n",
    "    for name in names:\n",
    "        tree = ET.parse(file_path +'/'+ name)\n",
    "        root = tree.getroot()\n",
    "        ## Get the labels\n",
    "        tag_list = []\n",
    "        loc_list = []\n",
    "        # get PHI labels if based on condition\n",
    "        if PHI_status == True:\n",
    "            PHI = [root[1][x].tag for x in range(len(root[1]))].index('PHI')\n",
    "            for k in range(PHI,len(root[1])):\n",
    "                tag_list.append((root[1][k].attrib['text'],root[1][k].tag))\n",
    "        \n",
    "        # get the rest of labels\n",
    "        for k in range(len(root[1])):\n",
    "            #if root[1][k].tag == 'SMOKER':\n",
    "            #    continue\n",
    "            if type == 'train':\n",
    "                if root[1][k].tag == 'FAMILY_HIST':\n",
    "                    continue\n",
    "            \n",
    "            for m in range(len(root[1][k])):\n",
    "                if root[1][k][m].attrib.keys().__contains__('text') == False:\n",
    "                    continue\n",
    "                tag_list.append((root[1][k][m].attrib['text'],root[1][k][m].tag))\n",
    "                loc_list.append((root[1][k][m].attrib['start'],root[1][k][m].attrib['end']))\n",
    "        df['annotation'][n] = tag_list\n",
    "        df['loc'][n] = loc_list\n",
    "        n+=1\n",
    "    return df\n",
    "\n",
    "all_1 = to_df(names_1,all1_df, trainingpath1, PHI_status = False, type = 'train')\n",
    "all_2 = to_df(names_2,all2_df, trainingpath2, PHI_status = False, type = 'train')\n",
    "test_df = to_df(names_3,test_df, testingpath, PHI_status = False, type='test')\n",
    "\n",
    "train_df = pd.concat([all_1, all_2], ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------Next section-----------------------------------------------------------------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pre-processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define functions to merge partial overlapped text\n",
    "## example: \"I like apple\" + \"apple that is red\" --> \"I like apple that is red\"\n",
    "## ls1 needs to be at the left of ls2 in the text\n",
    "def intersection(ls1, ls2):\n",
    "    index = [i for i, x in enumerate([x == ls2[0] for x in ls1]) if x]\n",
    "    if index[-1] == len(ls1)-1:\n",
    "        index = index[:-1]\n",
    "    cut = 10000\n",
    "    eva_temp = 10000\n",
    "    for i in index:\n",
    "        if (len(ls1) -i) < len(ls2):\n",
    "            l = len(ls1) -i\n",
    "        else:\n",
    "            l = len(ls2)\n",
    "        eva = sum([ls1[x+i] != ls2[x] for x in range(l)])\n",
    "        if eva < eva_temp:\n",
    "            cut = i\n",
    "            eva_temp = eva\n",
    "    out = \"\".join(ls1[0:cut]+ls2)\n",
    "    return out\n",
    "\n",
    "## define pre-process function\n",
    "## preprocess tagged text and location\n",
    "def pre_process(input):\n",
    "    df = input.copy()\n",
    "    for i in range(df.shape[0]):  \n",
    "        for j in range(len(df['annotation'][i])):\n",
    "                ## remove extra spaces in the beginning and end of the annotation\n",
    "                if re.search(\"^ +.*\",df['annotation'][i][j][0]) != None or re.search(\".* +$\",df['annotation'][i][j][0]) != None:\n",
    "                    front = len(df['annotation'][i][j][0]) - len(re.sub(\"^ +\",\"\",df['annotation'][i][j][0]))\n",
    "                    end = len(df['annotation'][i][j][0]) - len(re.sub(\" +$\",\"\",df['annotation'][i][j][0]))\n",
    "                    df['loc'][i][j] = (str(int(df['loc'][i][j][0])+front),str(int(df['loc'][i][j][1])-end))\n",
    "                    df['annotation'][i][j] = (re.sub(\" +$\",\"\", re.sub(\"^ +\",\"\",df['annotation'][i][j][0])),df['annotation'][i][j][1])\n",
    "                ## fix \"Record\" in \"Record date\" taged as SMOKER\n",
    "                if int(df['loc'][i][j][0]) == df['text'][i].find('Record'): \n",
    "                    df['loc'][i][j] = ('','')\n",
    "                    df['annotation'][i][j] = ('','')\n",
    "                    \n",
    "    return df\n",
    "\n",
    "## main function to remove duplicated tags\n",
    "## example: 1) \"I like apple that is red\" & \"I like apple\"; 2) \"I like apple\" + \"apple that is red\"\n",
    "def rm_dup(input):\n",
    "    df = input.copy()\n",
    "    symbol = [\",\",\".\",\"-\"]\n",
    "    for i in range(df.shape[0]):\n",
    "        for j in range(len(df['annotation'][i])):\n",
    "            ## used k starts at j+1 to avoid self compare\n",
    "            for k in np.arange(j+1,len(df['annotation'][i])):\n",
    "                ## move on if the compared lables are (\"\",\"\") due to ealier process\n",
    "                if df['loc'][i][j] == ('',''):\n",
    "                    break\n",
    "                if df['loc'][i][k] == ('',''):\n",
    "                    continue\n",
    "\n",
    "                ## find location contained within each other (\"I like apple that is red\" & \"I like apple\")\n",
    "                if int(df['loc'][i][j][0]) >= int(df['loc'][i][k][0]) and int(df['loc'][i][j][1]) <= int(df['loc'][i][k][1]):\n",
    "                    df['loc'][i][j] = ('','')\n",
    "                    df['annotation'][i][j] = ('','')\n",
    "                    continue\n",
    "                \n",
    "                elif int(df['loc'][i][j][0]) <= int(df['loc'][i][k][0]) and int(df['loc'][i][j][1]) >= int(df['loc'][i][k][1]):\n",
    "                    df['loc'][i][k] = ('','')\n",
    "                    df['annotation'][i][k] = ('','')\n",
    "                    continue\n",
    "\n",
    "                ## find location that overlap (\"I like apple\" + \"apple that is red\")\n",
    "                if int(df['loc'][i][j][0]) < int(df['loc'][i][k][0]) and int(df['loc'][i][j][1]) < int(df['loc'][i][k][1]) and int(df['loc'][i][j][1]) > int(df['loc'][i][k][0]):\n",
    "                    new_s = intersection(df['annotation'][i][j][0],df['annotation'][i][k][0])\n",
    "                    df['annotation'][i][j] = (new_s,df['annotation'][i][j][1])\n",
    "                    df['loc'][i][j] = (df['loc'][i][j][0],df['loc'][i][k][1])\n",
    "                    df['loc'][i][k] = ('','')\n",
    "                    df['annotation'][i][k] = ('','')\n",
    "                    continue\n",
    "            \n",
    "                elif int(df['loc'][i][j][0]) > int(df['loc'][i][k][0]) and int(df['loc'][i][j][1]) > int(df['loc'][i][k][1]) and int(df['loc'][i][j][0]) < int(df['loc'][i][k][1]):\n",
    "                    #print(i,j,k)\n",
    "                    #the order here matters, the first one should be the left most\n",
    "                    new_s = intersection(df['annotation'][i][k][0],df['annotation'][i][j][0])\n",
    "                    df['annotation'][i][k] = (new_s,df['annotation'][i][k][1])\n",
    "                    df['loc'][i][k] = (df['loc'][i][k][0],df['loc'][i][j][1])\n",
    "                    df['loc'][i][j] = ('','')\n",
    "                    df['annotation'][i][j] = ('','')\n",
    "                    continue\n",
    "\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocess train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## preprocess the data\n",
    "train_df = pre_process(train_df)\n",
    "train_n = rm_dup(train_df)\n",
    "train_n = rm_dup(train_n)\n",
    "\n",
    "test_df = pre_process(test_df)\n",
    "test_n = rm_dup(test_df)\n",
    "test_n = rm_dup(test_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## remove all the (\"\",\"\")\n",
    "for j in range(train_n.shape[0]):\n",
    "    train_n['annotation'][j] = [train_n['annotation'][j][i] for i in range(len(train_n['annotation'][j])) if train_n['annotation'][j][i][0] != '']\n",
    "    train_n['loc'][j] = [train_n['loc'][j][i] for i in range(len(train_n['loc'][j])) if train_n['loc'][j][i][0] != '']\n",
    "    ## order the tags by their starting position to avoid issue with finding text\n",
    "    ## example: \"I like red apple that is red\" {(\"red\",pos1), (\"red apple\", pos2)} --> \"I like XXX apple that is red\" {(\"red apple\", pos2)}\n",
    "    ## This issue originates how to match predicted back to original text after all the preprocessing where location info doesn't match\n",
    "    start = np.array([int(train_n['loc'][j][i][0]) for i in range(len(train_n['loc'][j]))])\n",
    "    order = start.argsort()\n",
    "    train_n['annotation'][j] = [train_n['annotation'][j][i] for i in order]\n",
    "    train_n['loc'][j] = [train_n['loc'][j][i] for i in order]\n",
    "train = train_n.drop('loc', axis=1)\n",
    "train.head()\n",
    "\n",
    "for j in range(test_n.shape[0]):\n",
    "    test_n['annotation'][j] = [test_n['annotation'][j][i] for i in range(len(test_n['annotation'][j])) if test_n['annotation'][j][i][0] != '']\n",
    "    test_n['loc'][j] = [test_n['loc'][j][i] for i in range(len(test_n['loc'][j])) if test_n['loc'][j][i][0] != '']\n",
    "    start = np.array([int(test_n['loc'][j][i][0]) for i in range(len(test_n['loc'][j]))])\n",
    "    order = start.argsort()\n",
    "    test_n['annotation'][j] = [test_n['annotation'][j][i] for i in order]\n",
    "    test_n['loc'][j] = [test_n['loc'][j][i] for i in order]\n",
    "test = test_n.drop('loc', axis=1)\n",
    "test.shape[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### modify text(eg. remove stopwords, changing coronary artery disease to CAD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "sw = stopwords.words('english')\n",
    "negat = [\"no\", \"nor\", \"not\",\"don't\",\"didn't\",\"doesn't\",\"isn't\",\"aren't\",\"wasn't\",\"weren't\",\"haven't\",\"hasn't\",\"hadn't\",\"won't\",\"wouldn't\",\"shouldn't\",\"can't\",\"couldn't\",\"mustn\",\"mustn't\",\"mightn't\",\"mightn't\",\"needn't\",\"needn't\",\"oughtn't\",\"shan't\",\"shan't\",\"shouldn't\",\"wasn't\",\"weren't\",\"won't\",\"wouldn't\",\"t\",\"shouldn\",\"wasn\",\"weren\",\"won\",\"wouldn\",\"can\",\"couldn\",\"didn\",\"doesn\",\"hadn\",\"hasn\",\"haven\",\"isn\",\"mightn\",\"mustn\",\"needn\",\"oughtn\",\"shan\",\"shouldn\",\"wasn\",\"weren\",\"won\",\"wouldn\"]\n",
    "sw_n = [w for w in sw if w not in negat]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# remove stop words in text to match tags\n",
    "for i in range(train.shape[0]):\n",
    "    word_tokens = train['text'][i].strip().split()\n",
    "    filtered_sentence = [w for w in word_tokens if not w.lower() in sw_n]\n",
    "    train['text'][i] = ' '.join(filtered_sentence)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "train['text'] = train['text'].apply(lambda x: re.sub('coronary artery disease','CAD',x))\n",
    "train['text'] = train['text'].apply(lambda x: re.sub('Coronary artery disease','CAD',x))\n",
    "train['text'] = train['text'].apply(lambda x: re.sub('Coronary Artery Disease','CAD',x))\n",
    "train['text'] = train['text'].apply(lambda x: re.sub('Blood Pressure','BP',x))\n",
    "train['text'] = train['text'].apply(lambda x: re.sub('blood pressure','BP',x))\n",
    "train['text'] = train['text'].apply(lambda x: re.sub('Blood pressure','BP',x))\n",
    "train['text'] = train['text'].apply(lambda x: re.sub('blood Pressure','BP',x))\n",
    "train['text'] = train['text'].apply(lambda x: re.sub('&#8211','',x))\n",
    "#train['text'] = train['text'].apply(lambda x: re.sub(' p\\.o\\. ',' per oral ',x))\n",
    "#train['text'] = train['text'].apply(lambda x: re.sub(' h/o ',' had ',x))\n",
    "#train['text'] = train['text'].apply(lambda x: x.lower())'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for i in range(train.shape[0]):\n",
    "    for x in range(len(train['annotation'][i])):\n",
    "        word_tokens = train['annotation'][i][x][0].strip().split()\n",
    "        # converts the words in word_tokens to lower case and then checks whether \n",
    "        #they are present in stop_words or not\n",
    "        \n",
    "        filtered_sentence = [w for w in word_tokens if not w.lower() in sw_n] \n",
    "        tagged_things = ' '.join(filtered_sentence) \n",
    "\n",
    "        tagged_things = re.sub('coronary artery disease','CAD',tagged_things) \n",
    "        tagged_things = re.sub('Coronary artery disease','CAD',tagged_things)\n",
    "        tagged_things = re.sub('Coronary Artery Disease','CAD',tagged_things)\n",
    "        tagged_things = re.sub('Blood Pressure','BP',tagged_things)\n",
    "        tagged_things = re.sub('blood pressure','BP',tagged_things)\n",
    "        tagged_things = re.sub('Blood pressure','BP',tagged_things)\n",
    "        tagged_things = re.sub('blood Pressure','BP',tagged_things)\n",
    "        tagged_things = re.sub('&#8211','',tagged_things)\n",
    "        #tagged_things = re.sub(' p\\.o\\. ',' per oral ',tagged_things)\n",
    "        #tagged_things = re.sub(' h/o ',' had ',tagged_things)\n",
    "        train['annotation'][i][x] = (tagged_things,train['annotation'][i][x][1])'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### update info for corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## update info in corpus\n",
    "corpus['CleanedText'] = train['text']\n",
    "corpus['AnnotatedText'] = train['annotation']\n",
    "\n",
    "#Tag categories\n",
    "tagCategories = []\n",
    "for index,entry in enumerate(corpus['AnnotatedText']):\n",
    "    tagcatergories_eachfile = []\n",
    "    for entity in entry:\n",
    "        tagcatergories_eachfile.append(entity[1])\n",
    "    tagCategories.append(tagcatergories_eachfile)\n",
    "\n",
    "corpus['TagCategory'] = tagCategories\n",
    "tag_doc = []\n",
    "for index,entry in enumerate(corpus['TagCategory']):\n",
    "    tag_doc_eachfile = []\n",
    "    for i in range(len(entry)):\n",
    "        #just keep the unique tag category, store in doc-level tag\n",
    "        tag_doc_eachfile = list(set(entry))\n",
    "    tag_doc.append(tag_doc_eachfile)\n",
    "\n",
    "corpus['Tag_doc'] = tag_doc\n",
    "\n",
    "#save the corpus to a csv file\n",
    "corpus.to_csv('E:/JHU/课程/datadesign/NLP/machine_learning/corpus.csv',index=False,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_test['CleanedText'] = test['text']\n",
    "corpus_test['AnnotatedText'] = test['annotation']\n",
    "\n",
    "#Tag categories\n",
    "tagCategories = []\n",
    "for index,entry in enumerate(corpus_test['AnnotatedText']):\n",
    "    tagcatergories_eachfile = []\n",
    "    for entity in entry:\n",
    "        tagcatergories_eachfile.append(entity[1])\n",
    "    tagCategories.append(tagcatergories_eachfile)\n",
    "\n",
    "corpus_test['TagCategory'] = tagCategories\n",
    "tag_doc = []\n",
    "for index,entry in enumerate(corpus_test['TagCategory']):\n",
    "    tag_doc_eachfile = []\n",
    "    for i in range(len(entry)):\n",
    "        #just keep the unique tag category, store in doc-level tag\n",
    "        tag_doc_eachfile = list(set(entry))\n",
    "    tag_doc.append(tag_doc_eachfile)\n",
    "\n",
    "corpus_test['Real_tag_doc'] = tag_doc\n",
    "\n",
    "#save the corpus to a csv file\n",
    "corpus_test.to_csv('E:/JHU/课程/datadesign/NLP/machine_learning/corpus_test.csv',index=False,encoding='utf-8')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------Next section-----------------------------------------------------------------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create input for machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from difflib import SequenceMatcher\n",
    "import pickle\n",
    "\n",
    "## define function: get location to tag in text\n",
    "## string: original text   pattern: tagged text\n",
    "def matcher(string, pattern):\n",
    "    match_list = []\n",
    "    pattern = pattern.strip()\n",
    "    seqMatch = SequenceMatcher(None, string, pattern, autojunk=False)\n",
    "    match = seqMatch.find_longest_match(0, len(string), 0, len(pattern))\n",
    "    if (match.size == len(pattern)):\n",
    "        start = match.a\n",
    "        end = match.a + match.size\n",
    "        match_tup = (start, end)\n",
    "        ## replace matcheed tags with X to avoid double match\n",
    "        string = string.replace(pattern, \"X\" * len(pattern), 1)\n",
    "        match_list.append(match_tup)\n",
    "\n",
    "    return match_list, string\n",
    "\n",
    "## create word by word tag input file\n",
    "## s: original text   match_list: output from matcher()\n",
    "def create_labs(s,match_list):\n",
    "    labs = ['O' for i in range(len(s.split()))]\n",
    "    word_dict = pd.DataFrame({'word':s.split(),'label':labs})\n",
    "\n",
    "    for start, end, e_type in match_list:\n",
    "        index = len(re.findall(r' +',s[0:start]))-1\n",
    "        num_words = len(s[start:end].split())\n",
    "\n",
    "        if num_words > 1:\n",
    "            word_dict.loc[index,'label'] = e_type\n",
    "            for i in range(1,num_words):\n",
    "                word_dict.loc[index+i,'label'] = e_type\n",
    "        else:\n",
    "            word_dict.loc[index,'label'] = e_type\n",
    "    return word_dict\n",
    "\n",
    "#def clean(text):\n",
    "#    '''\n",
    "#    Just a helper fuction to add a space before the punctuations for better tokenization\n",
    "#    '''\n",
    "#    filters = [\"!\", \"#\", \"$\", \"%\", \"&\", \"(\", \")\", \"/\", \"*\", \".\", \":\", \";\", \"<\", \"=\", \">\", \"?\", \"@\", \"[\",\n",
    "#               \"\\\\\", \"]\", \"_\", \"`\", \"{\", \"}\", \"~\", \"'\"]\n",
    "#    for i in text:\n",
    "#        if i in filters:\n",
    "#            text = text.replace(i, \" \" + i)\n",
    "#            \n",
    "#    return text\n",
    "\n",
    "## integrate matcher)() and create_labs()\n",
    "def to_txt(df, corpus, filepath):\n",
    "    with open(filepath , 'w') as f:\n",
    "        n = 0\n",
    "        for text, annotation in zip(df.text, df.annotation):\n",
    "            #text = clean(text)\n",
    "            text_ = text    \n",
    "            print(df.index[df['text']== text_].tolist())    \n",
    "            match_list = []\n",
    "            for i in annotation:\n",
    "                a,text_= matcher(text_, i[0])\n",
    "                match_list.append((a[0][0], a[0][1], i[1]))\n",
    "\n",
    "            d = create_labs(text, match_list)\n",
    "\n",
    "            word_label = []\n",
    "            for i in range(d.shape[0]):\n",
    "                #f.writelines(d['word'][i] + ' ' + d['label'][i] +'\\n')\n",
    "                word_label.append(d['word'][i] + ' ' + d['label'][i])\n",
    "\n",
    "            corpus['Real_text_tag'][n] = word_label\n",
    "            n += 1\n",
    "           \n",
    "def main(input,corpus,save_path):\n",
    "\n",
    "    data = input\n",
    "    to_txt(data,corpus, save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './'\n",
    "main(train,corpus,path+'train(clean).txt')\n",
    "main(test,corpus_test,path+'test(clean).txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the corpus to a csv file\n",
    "corpus.to_csv('E:/JHU/课程/datadesign/NLP/machine_learning/corpus.csv',index=False,encoding='utf-8')\n",
    "corpus_test.to_csv('E:/JHU/课程/datadesign/NLP/machine_learning/corpus_test.csv',index=False,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## may need to load corpus\n",
    "\n",
    "traininglist = pd.DataFrame(columns=['file','text', 'label'])\n",
    "for index,entry in enumerate(corpus['Real_text_tag']):\n",
    "    trainingsublist = pd.DataFrame(np.zeros((len(entry), 3), dtype=object), columns=['file','text', 'label'])    \n",
    "    #make the text and label into two columns, and then concat them together\n",
    "    for i in range(len(entry)):\n",
    "        trainingsublist['text'][i] = entry[i].split()[0]\n",
    "        trainingsublist['label'][i] = entry[i].split()[1]\n",
    "    trainingsublist['file'] = index+1\n",
    "    traininglist = pd.concat([traininglist,trainingsublist],axis=0)\n",
    "\n",
    "\n",
    "    testinglist = pd.DataFrame(columns=['file','text', 'label'])\n",
    "for index,entry in enumerate(corpus_test['Real_text_tag']):\n",
    "    testingsublist = pd.DataFrame(np.zeros((len(entry), 3), dtype=object), columns=['file','text', 'label'])\n",
    "    #make the text and label into two columns, and then concat them together\n",
    "    for i in range(len(entry)):\n",
    "        testingsublist['text'][i] = entry[i].split()[0]\n",
    "        testingsublist['label'][i] = entry[i].split()[1]\n",
    "    testingsublist['file'] = index+1\n",
    "    testinglist = pd.concat([testinglist,testingsublist],axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### modify text(eg. remove stopwords, changing coronary artery disease to CAD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for i in range(test.shape[0]):\n",
    "    word_tokens = test['text'][i].strip().split()\n",
    "    filtered_sentence = [w for w in word_tokens if not w.lower() in sw_n]\n",
    "    test['text'][i] = ' '.join(filtered_sentence)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "test['text'] = test['text'].apply(lambda x: re.sub('coronary artery disease','CAD',x))\n",
    "test['text'] = test['text'].apply(lambda x: re.sub('Coronary artery disease','CAD',x))\n",
    "test['text'] = test['text'].apply(lambda x: re.sub('Coronary Artery Disease','CAD',x))\n",
    "test['text'] = test['text'].apply(lambda x: re.sub('Blood Pressure','BP',x))\n",
    "test['text'] = test['text'].apply(lambda x: re.sub('blood pressure','BP',x))\n",
    "test['text'] = test['text'].apply(lambda x: re.sub('Blood pressure','BP',x))\n",
    "test['text'] = test['text'].apply(lambda x: re.sub('blood Pressure','BP',x))\n",
    "test['text'] = test['text'].apply(lambda x: re.sub('&#8211','',x))\n",
    "#test['text'] = test['text'].apply(lambda x: re.sub(' p\\.o\\. ','per oral',x))\n",
    "#test['text'] = test['text'].apply(lambda x: re.sub(' h/o ','had',x))\n",
    "#test['text'] = test['text'].apply(lambda x: x.lower())'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for i in range(test.shape[0]):\n",
    "    for x in range(len(test['annotation'][i])):\n",
    "        word_tokens = test['annotation'][i][x][0].strip().split()\n",
    "        # converts the words in word_tokens to lower case and then checks whether \n",
    "        #they are present in stop_words or not\n",
    "        filtered_sentence = [w for w in word_tokens if not w.lower() in sw_n]\n",
    "        tagged_things = ' '.join(filtered_sentence)\n",
    "        tagged_things = re.sub('coronary artery disease','CAD',tagged_things)\n",
    "        tagged_things = re.sub('Coronary artery disease','CAD',tagged_things)\n",
    "        tagged_things = re.sub('Coronary Artery Disease','CAD',tagged_things)\n",
    "        tagged_things = re.sub('Blood Pressure','BP',tagged_things)\n",
    "        tagged_things = re.sub('blood pressure','BP',tagged_things)\n",
    "        tagged_things = re.sub('Blood pressure','BP',tagged_things)\n",
    "        tagged_things = re.sub('blood Pressure','BP',tagged_things)\n",
    "        tagged_things = re.sub('&#8211','',tagged_things)\n",
    "        #tagged_things = re.sub(' p\\.o\\. ',' per oral ',tagged_things)\n",
    "        #tagged_things = re.sub(' h/o ','had',tagged_things)\n",
    "        test['annotation'][i][x] = (tagged_things,test['annotation'][i][x][1])'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------Next section-----------------------------------------------------------------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling (Naive Bayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load corpus if already have one\n",
    "\n",
    "traininglist = pd.DataFrame(columns=['file','text', 'label'])\n",
    "for index,entry in enumerate(corpus['Real_text_tag']):\n",
    "    trainingsublist = pd.DataFrame(np.zeros((len(entry), 3), dtype=object), columns=['file','text', 'label'])    \n",
    "    #make the text and label into two columns, and then concat them together\n",
    "    for i in range(len(entry)):\n",
    "        trainingsublist['text'][i] = entry[i].split()[0]\n",
    "        trainingsublist['label'][i] = entry[i].split()[1]\n",
    "    trainingsublist['file'] = index+1\n",
    "    traininglist = pd.concat([traininglist,trainingsublist],axis=0)\n",
    "\n",
    "\n",
    "    testinglist = pd.DataFrame(columns=['file','text', 'label'])\n",
    "for index,entry in enumerate(corpus_test['Real_text_tag']):\n",
    "    testingsublist = pd.DataFrame(np.zeros((len(entry), 3), dtype=object), columns=['file','text', 'label'])\n",
    "    #make the text and label into two columns, and then concat them together\n",
    "    for i in range(len(entry)):\n",
    "        testingsublist['text'][i] = entry[i].split()[0]\n",
    "        testingsublist['label'][i] = entry[i].split()[1]\n",
    "    testingsublist['file'] = index+1\n",
    "    testinglist = pd.concat([testinglist,testingsublist],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingtext = traininglist.drop(['file','label'],axis=1)\n",
    "#print(trainingtext)\n",
    "traininglabel = traininglist['label']\n",
    "\n",
    "v = DictVectorizer(sparse=True)\n",
    "x_train = v.fit_transform(trainingtext.to_dict('records'))\n",
    "y_train = traininglabel\n",
    "\n",
    "classes = np.unique(traininglabel)\n",
    "classes = classes.tolist()\n",
    "\n",
    "testingtext = testinglist.drop(['file','label'],axis=1)\n",
    "testinglabel = testinglist['label']\n",
    "\n",
    "x_test = v.transform(testingtext.to_dict('records'))\n",
    "y_test = testinglabel\n",
    "\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_classes = classes.copy()\n",
    "## O class bias evaluation, remove\n",
    "new_classes.remove('O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive bayes\n",
    "nb = MultinomialNB(alpha=.0005)\n",
    "nb.partial_fit(x_train, y_train,classes=classes)\n",
    "\n",
    "print (classification_report(y_pred=nb.predict(x_test), y_true=y_test, labels=new_classes))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "y_pred = nb.predict(x_test)\n",
    "conf_mat = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d',\n",
    "            xticklabels=classes, yticklabels=classes)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vadicationlist = testinglist.copy()\n",
    "vadicationlist.insert(3, 'pred_label', '')\n",
    "\n",
    "vadicationlist['pred_label'] = y_pred\n",
    "\n",
    "vadicationlist.groupby('pred_label').count().sort_values(by='text',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vadicationlist.groupby(['label']).count().sort_values(by='text',ascending=False).drop(['file','pred_label'],axis=1))\n",
    "print(vadicationlist.groupby(['pred_label']).count().sort_values(by='text',ascending=False).drop(['file','label'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the different result\n",
    "wrongresult = vadicationlist[vadicationlist['label']!=vadicationlist['pred_label']].copy()\n",
    "print(wrongresult)\n",
    "sorted_wrong_result = wrongresult.groupby('text').count().sort_values(by='label', ascending=False) #sort the wrong result by the number of times it appears\n",
    "print(sorted_wrong_result[:15])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wrongresult[wrongresult['text'] == 'hypertension,'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vadicationlist['file']-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#group the vadicationlist by file\n",
    "vadicationlist_grouped = vadicationlist.groupby('file')\n",
    "vadicationlist_grouped_list = []\n",
    "for name,group in vadicationlist_grouped:\n",
    "    vadicationlist_grouped_list.append(group)\n",
    "\n",
    "print(vadicationlist_grouped_list[0])\n",
    "\n",
    "#delete the 'file' column\n",
    "for i in range(len(vadicationlist_grouped_list)):\n",
    "    vadicationlist_grouped_list[i] = vadicationlist_grouped_list[i].drop(['file'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vadicationlist_grouped_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vadicationlist_grouped_list[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pred_text_tag = []\n",
    "for i in range(len(vadicationlist_grouped_list)):\n",
    "    Pred_text_tag_eachfile = []\n",
    "    for j in range(len(vadicationlist_grouped_list[i])):\n",
    "        Pred_text_tag_eachfile.append(vadicationlist_grouped_list[i]['text'][j]+' '+vadicationlist_grouped_list[i]['label'][j]+' '+vadicationlist_grouped_list[i]['pred_label'][j])\n",
    "    Pred_text_tag.append(Pred_text_tag_eachfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(Pred_text_tag[0]))\n",
    "print(len(Pred_text_tag[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_test['Pred_text_tag'] = Pred_text_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_test['Pred_text_tag'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the corpus to a csv file\n",
    "corpus_test.to_csv('E:/JHU/课程/datadesign/NLP/machine_learning/corpus_test.csv',index=False,encoding='utf-8')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc-level Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pred_doc_tag = []\n",
    "#delete repeated tags\n",
    "for i in range(len(vadicationlist_grouped_list)):\n",
    "    Pred_doc_tag_eachfile = []\n",
    "    for j in range(len(vadicationlist_grouped_list[i])):\n",
    "        Pred_doc_tag_eachfile.append(vadicationlist_grouped_list[i]['pred_label'][j])\n",
    "    Pred_doc_tag_eachfile = list(set(Pred_doc_tag_eachfile))\n",
    "    Pred_doc_tag_eachfile.remove('O')\n",
    "    Pred_doc_tag.append(Pred_doc_tag_eachfile)\n",
    "#vadicationlist_grouped_list[0]['pred_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Pred_doc_tag[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_test['Pred_tag_doc'] = Pred_doc_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the corpus to a csv file\n",
    "corpus_test.to_csv('E:/JHU/课程/datadesign/NLP/machine_learning/corpus_test.csv',index=False,encoding='utf-8')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule-based doc-level prediction for SMOKER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file2tag = {}\n",
    "import os\n",
    "\n",
    "with open('./TestingFAMILY_HIST.txt','r') as f:\n",
    "    for line in f:\n",
    "        lineInfo = line.strip().split(' ')\n",
    "        if len(lineInfo) > 1:\n",
    "            fileName = lineInfo[1]\n",
    "            if fileName in file2tag: file2tag[fileName].append(lineInfo[2:])\n",
    "            else: file2tag[fileName] = [lineInfo[2:]]\n",
    "\n",
    "SMOKER_path = './Smoker/'\n",
    "\n",
    "for fileName in os.listdir(testingpath): #Input EHRs\n",
    "    with open(testingpath+'/'+fileName,'r') as f:\n",
    "        with open(SMOKER_path+fileName,'w') as fw: #Can change this to any folder name you want (this is where it puts the outputs)\n",
    "            f.readline()\n",
    "            f.readline()\n",
    "            fileString = ''\n",
    "            tags = False\n",
    "            tagsList = []\n",
    "            doccount = 0\n",
    "            fw.write(\"<?xml version='1.0' encoding='UTF-8'?>\\n\")\n",
    "            fw.write(\"<root>\\n\")\n",
    "            for line in f.readlines():\n",
    "                fileString += line\n",
    "                if tags: tagsList.append(line)\n",
    "                else: fw.write(line)\n",
    "                if '<TAGS>' in line: tags = True\n",
    "            histKnown = False\n",
    "            for tag in file2tag[fileName]:\n",
    "                typeOfTag = tag[-1].strip().replace('\\n','').replace('\\t','')\n",
    "                if typeOfTag == 'familyhistory':\n",
    "                    histKnown = True\n",
    "            if not histKnown:\n",
    "                fw.write(\"\\t<FAMILY_HIST id=\\\"DOC\"+str(doccount)+\"\\\" indicator=\\\"not present\\\"/>\\n\")\n",
    "                doccount += 1\n",
    "            else:\n",
    "                fw.write(\"\\t<FAMILY_HIST id=\\\"DOC\"+str(doccount)+\"\\\" indicator=\\\"present\\\"/>\\n\")\n",
    "                doccount += 1\n",
    "            fw.write('\\t</TAGS>\\n')\n",
    "            fw.write('</root>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMOKER_prediction = []\n",
    "\n",
    "for file in os.listdir(SMOKER_path):\n",
    "    tree = ET.parse(SMOKER_path+file)\n",
    "    root = tree.getroot()\n",
    "    tags = root.findall('TAGS')\n",
    "    for tag in tags:\n",
    "        for child in tag:\n",
    "            if child.tag == 'FAMILY_HIST':\n",
    "                #in family history, the indicator is either present or not present, store it in the list\n",
    "                SMOKER_prediction.append(child.attrib['indicator']) \n",
    "                \n",
    "\n",
    "print(len(SMOKER_prediction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count the number of 'present'\n",
    "print(SMOKER_prediction.count('present'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(SMOKER_prediction)):\n",
    "    if SMOKER_prediction[i] == 'present':\n",
    "        #if the indicator is present, add the tag 'FAMILY_HIST' to the the doc-level tag list\n",
    "        Pred_doc_tag[i].append('FAMILY_HIST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count the number of 'FAMILY_HIST' in the doc-level tag list\n",
    "count = 0\n",
    "for i in range(len(Pred_doc_tag)):\n",
    "    if 'FAMILY_HIST' in Pred_doc_tag[i]:\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_test['Pred_tag_doc'] = Pred_doc_tag #update the doc-level tag list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the corpus to a csv file\n",
    "corpus_test.to_csv('E:/JHU/课程/datadesign/NLP/machine_learning/corpus_test.csv',index=False,encoding='utf-8')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Evaluation = pd.DataFrame(columns=['file','Real_tag_doc','Pred_tag_doc'])\n",
    "Evaluation['file'] = corpus_test.index\n",
    "Evaluation['Real_tag_doc'] = corpus_test['Real_tag_doc']\n",
    "Evaluation['Pred_tag_doc'] = Pred_doc_tag\n",
    "\n",
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Evaluation['Real_tag_doc'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_each(list, taget_tag):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    TN = 0\n",
    "    for i in range(len(list)):\n",
    "        if taget_tag in list['Real_tag_doc'][i]:\n",
    "            if taget_tag in list['Pred_tag_doc'][i]:\n",
    "                TP += 1\n",
    "            else:\n",
    "                FN += 1\n",
    "        else:\n",
    "            if taget_tag in list['Pred_tag_doc'][i]:\n",
    "                FP += 1\n",
    "            else:\n",
    "                TN += 1\n",
    "            \n",
    "    #print('TP:',TP)\n",
    "    #print('FP:',FP)\n",
    "    #print('FN:',FN)\n",
    "    return TP,FP,FN,TN\n",
    "\n",
    "def evaluate_matrix(list, taget_tag_list = ['SMOKER', 'FAMILY_HIST']):\n",
    "    \n",
    "    score_matrix = pd.DataFrame(columns=['target_tag','TP','FP','FN','TN','precision','recall','F1','Support'])\n",
    "\n",
    "    for taget_tag in taget_tag_list:\n",
    "        score_matrix_each = pd.DataFrame(columns=['target_tag','TP','FP','FN','TN','precision','recall','F1','Support'])\n",
    "        TP,FP,FN,TN = evaluate_each(list, taget_tag)\n",
    "        if TP+FP == 0:\n",
    "            if TP == 0:\n",
    "                precision = 0\n",
    "            else:\n",
    "                precision = 1\n",
    "        else:\n",
    "            precision = TP/(TP+FP)\n",
    "        if TP+FN == 0:\n",
    "            if TP == 0:\n",
    "                recall = 0\n",
    "            else:\n",
    "                recall = 1\n",
    "        else:\n",
    "            recall = TP/(TP+FN)\n",
    "        if precision+recall == 0:\n",
    "            if precision*recall == 0:\n",
    "                F1 = 0\n",
    "            else:\n",
    "                F1 = 1\n",
    "        else:\n",
    "            F1 = 2*precision*recall/(precision+recall)\n",
    "        \n",
    "        score_matrix_each['target_tag'] = [taget_tag]\n",
    "        score_matrix_each['TP'] = [TP]\n",
    "        score_matrix_each['FP'] = [FP]\n",
    "        score_matrix_each['FN'] = [FN]\n",
    "        score_matrix_each['TN'] = [TN]\n",
    "        score_matrix_each['precision'] = [precision]\n",
    "        score_matrix_each['recall'] = [recall]\n",
    "        score_matrix_each['F1'] = [F1]\n",
    "        score_matrix_each['Support'] = [TP+FN]\n",
    "\n",
    "        \n",
    "        score_matrix = pd.concat([score_matrix,score_matrix_each],axis=0)\n",
    "        \n",
    "    return score_matrix\n",
    "\n",
    "def total_score(score_matrix):  \n",
    "    support_sum = score_matrix['Support'].sum()\n",
    "    support_proportion = score_matrix['Support']/support_sum\n",
    "\n",
    "    TP_sum = score_matrix['TP'].sum()\n",
    "    FP_sum = score_matrix['FP'].sum()\n",
    "    FN_sum = score_matrix['FN'].sum()\n",
    "    TN_sum = score_matrix['TN'].sum()\n",
    "    \n",
    "    weighted_precision = (score_matrix['precision']*support_proportion).sum()\n",
    "    weighted_recall = (score_matrix['recall']*support_proportion).sum()\n",
    "    weighted_F1 = (score_matrix['F1']*support_proportion).sum()\n",
    "\n",
    "    \n",
    "    score_matrix = score_matrix.append({'target_tag':'Total_macro','TP':TP_sum,'FP':FP_sum,'FN':FN_sum, 'TN':TN_sum,\n",
    "                                        'precision':score_matrix['precision'].mean(),'recall':score_matrix['recall'].mean(),'F1':score_matrix['F1'].mean(), 'Support':support_sum},ignore_index=True)\n",
    "    score_matrix = score_matrix.append({'target_tag':'Total_micro','TP':TP_sum,'FP':FP_sum,'FN':FN_sum, 'TN':TN_sum,\n",
    "                                        'precision':score_matrix['TP'].sum()/(score_matrix['TP'].sum()+score_matrix['FP'].sum()),'recall':score_matrix['TP'].sum()/(score_matrix['TP'].sum()+score_matrix['FN'].sum()),'F1':2*score_matrix['TP'].sum()/(2*score_matrix['TP'].sum()+score_matrix['FP'].sum()+score_matrix['FN'].sum()), 'Support':support_sum},ignore_index=True)\n",
    "    score_matrix = score_matrix.append({'target_tag':'Total_weighted','TP':TP_sum,'FP':FP_sum,'FN':FN_sum, 'TN':TN_sum,\n",
    "                                        'precision':weighted_precision,'recall':weighted_recall,'F1':weighted_F1, 'Support':support_sum},ignore_index=True)\n",
    "    \n",
    "    #print(score_matrix)\n",
    "    return score_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Evaluate_Matrix = evaluate_matrix(Evaluation,taget_tag_list =['MEDICATION','CAD','DIABETES','SMOKER','HYPERTENSION','HYPERLIPIDEMIA','OBESE','FAMILY_HIST'])\n",
    "\n",
    "#no smoker\n",
    "#Evaluate_Matrix = evaluate_matrix(Evaluation,taget_tag_list =['MEDICATION','CAD','DIABETES','HYPERTENSION','HYPERLIPIDEMIA','OBESE','FAMILY_HIST'])\n",
    "Evaluate_Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_score(Evaluate_Matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the precision recall F1 \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_score(score_matrix):\n",
    "    #sco\n",
    "    score_matrix = score_matrix.sort_values(by=['F1'],ascending=False)\n",
    "    score_matrix = score_matrix.reset_index(drop=True)\n",
    "    score_matrix = score_matrix.drop(['TP','FP','FN','TN','Support'],axis=1)\n",
    "    score_matrix = score_matrix.set_index('target_tag')\n",
    "    score_matrix.plot(kind='barh',figsize=(6,6),fontsize=9, colormap='Paired')\n",
    "    plt.show()\n",
    "\n",
    "plot_score(Evaluate_Matrix)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy\n",
    "accuracy = (Evaluate_Matrix['TP'].sum()+Evaluate_Matrix['TN'].sum())/(Evaluate_Matrix['TP'].sum()+Evaluate_Matrix['TN'].sum()+Evaluate_Matrix['FP'].sum()+Evaluate_Matrix['FN'].sum())\n",
    "print('accuracy:',accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "45c8c113c89725fba772e1ca4fde30d9f5141ae7bbb9f5f94dfdaac42e209b35"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

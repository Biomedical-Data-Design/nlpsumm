{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(489694, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(53284, 9)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read txt file\n",
    "def read_txt(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        data = f.readlines()\n",
    "    return data\n",
    "\n",
    "\n",
    "traininglist1 = read_txt('../BERT/data_processed/train(no_BIO).txt')\n",
    "#traininglist2 = read_txt('./trainingdata2_noPHI.txt')\n",
    "#traininglist = traininglist1 + traininglist2\n",
    "#traininglist3 = read_txt('./train_withoutphi.txt')\n",
    "\n",
    "#you could pick one of the trainingset to train the model. \n",
    "#Traininglist1 is the first trainingset, traininglist2 is the second trainingset, traininglist3 is the combination.\n",
    "traininglist = traininglist1\n",
    "\n",
    "#print(list)\n",
    "for i in range(len(traininglist)):\n",
    "    traininglist[i] = traininglist[i].split()\n",
    "#print(list)\n",
    "\n",
    "trainingdataframe = pd.DataFrame(traininglist, columns=['text', 'label'])\n",
    "print(trainingdataframe.shape)\n",
    "trainingdataframe.head()\n",
    "\n",
    "df_training = trainingdataframe.fillna(method='ffill')\n",
    "df_training.text.nunique(), df_training.label.nunique()  #check the number of unique words and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CAD</td>\n",
       "      <td>5620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DIABETES</td>\n",
       "      <td>2284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FAMILY_HIST</td>\n",
       "      <td>254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HYPERLIPIDEMIA</td>\n",
       "      <td>590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HYPERTENSION</td>\n",
       "      <td>2188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MEDICATION</td>\n",
       "      <td>6090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>O</td>\n",
       "      <td>470029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>OBESE</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SMOKER</td>\n",
       "      <td>2347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            label  counts\n",
       "0             CAD    5620\n",
       "1        DIABETES    2284\n",
       "2     FAMILY_HIST     254\n",
       "3  HYPERLIPIDEMIA     590\n",
       "4    HYPERTENSION    2188\n",
       "5      MEDICATION    6090\n",
       "6               O  470029\n",
       "7           OBESE     292\n",
       "8          SMOKER    2347"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_training.groupby('label').size().reset_index(name='counts') #check the number of each label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CAD</td>\n",
       "      <td>3873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O</td>\n",
       "      <td>333009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  counts\n",
       "0   CAD    3873\n",
       "1     O  333009"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#delete the rows with label 'O', and generate a new dataframe without 'O' for training without 'O'\n",
    "df_training.loc[df_training.label != 'CAD',\"label\"] = 'O'\n",
    "df_training.groupby('label').size().reset_index(name='counts')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(316727, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Record</td>\n",
       "      <td>SMOKER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>date:</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2069-04-07</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mr.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Villegas</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         text   label\n",
       "0      Record  SMOKER\n",
       "1       date:       O\n",
       "2  2069-04-07       O\n",
       "3         Mr.       O\n",
       "4    Villegas       O"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read txt file\n",
    "testinglist = read_txt('../BERT/data_processed/test(no_BIO).txt')\n",
    "#print(list)\n",
    "\n",
    "for i in range(len(testinglist)):\n",
    "    testinglist[i] = testinglist[i].split()\n",
    "#print(list)\n",
    "\n",
    "testingdataframe = pd.DataFrame(testinglist,columns=['text','label'])\n",
    "print(testingdataframe.shape)\n",
    "testingdataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40140, 9)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_testing = testingdataframe.fillna(method='ffill')\n",
    "df_testing.text.nunique(), df_testing.label.nunique() #check the number of unique words and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CAD</td>\n",
       "      <td>3951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DIABETES</td>\n",
       "      <td>1676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FAMILY_HIST</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HYPERLIPIDEMIA</td>\n",
       "      <td>493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HYPERTENSION</td>\n",
       "      <td>1263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MEDICATION</td>\n",
       "      <td>4148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>O</td>\n",
       "      <td>303157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>OBESE</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SMOKER</td>\n",
       "      <td>1657</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            label  counts\n",
       "0             CAD    3951\n",
       "1        DIABETES    1676\n",
       "2     FAMILY_HIST     214\n",
       "3  HYPERLIPIDEMIA     493\n",
       "4    HYPERTENSION    1263\n",
       "5      MEDICATION    4148\n",
       "6               O  303157\n",
       "7           OBESE     168\n",
       "8          SMOKER    1657"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_testing.groupby('label').size().reset_index(name='counts') #check the number of each label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with o class———choose one of the following training and testing method to run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize the text samples into a 2D integer tensor and split the trainingdata into a training set and a validation set for primary results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((235817, 42418), (235817,), (101065, 42418), (101065,))"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingtext_with_o = df_training.drop('label',axis=1)  #drop the label column\n",
    "traininglabel_with_o = df_training.label.values #get the label column\n",
    "#print (trainingtext_with_o)\n",
    "#print(traininglabel_with_o)\n",
    "\n",
    "v = DictVectorizer(sparse=True) #sparse=True means the output is a sparse matrix\n",
    "trainingtext_with_o = v.fit_transform(trainingtext_with_o.to_dict('records')) #to_dict('records') means the output is a list of dictionaries\n",
    "#print(trainingtext_with_o)\n",
    "\n",
    "classes = np.unique(traininglabel_with_o) #get the unique labels as classes for performance evaluation\n",
    "classes = classes.tolist() #convert the numpy array to list\n",
    "#print(classes)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(trainingtext_with_o, traininglabel_with_o, test_size = 0.3, random_state=0) \n",
    "\n",
    "x_train.shape, y_train.shape,x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df_training.drop('label',axis=1)  #drop the label column\n",
    "y_train = df_training.label.values #get the label column\n",
    "x_test = df_testing.drop('label',axis=1)  #drop the label column\n",
    "y_test = df_testing.label.values #get the label column\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leste\\AppData\\Local\\Temp\\ipykernel_1212\\4215444867.py:1: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tt = x_train.append(x_test)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(806421, 73054)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tt = x_train.append(x_test)\n",
    "ttt =  v.fit_transform(tt.to_dict('records'))\n",
    "\n",
    "ttt.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(489694, 1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train = ttt[:x_train.shape[0]]\n",
    "x_test = ttt[x_train.shape[0]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['O', 'O', 'O', ..., 'O', 'O', 'O'], dtype=object)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# make two dataframes, each with only one class \n",
    "majority_df = x_train[y_train == \"O\"]\n",
    "minority_df = x_train[y_train != \"O\"]\n",
    "\n",
    "minority_df.shape, majority_df.shape\n",
    "type(majority_df)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'majority_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [10], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mrandom\u001b[39;00m\n\u001b[0;32m      4\u001b[0m random\u001b[39m.\u001b[39mseed(\u001b[39m72\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m row \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mpermutation(majority_df\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])[:\u001b[39m2\u001b[39m\u001b[39m*\u001b[39mminority_df\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]]\n\u001b[0;32m      6\u001b[0m t_lab \u001b[39m=\u001b[39m y_train[y_train \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mCAD\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m      7\u001b[0m d_majority_df \u001b[39m=\u001b[39m majority_df[row]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'majority_df' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import vstack\n",
    "import random\n",
    "random.seed(72)\n",
    "row = np.random.permutation(majority_df.shape[0])[:2*minority_df.shape[0]]\n",
    "t_lab = y_train[y_train == \"CAD\"]\n",
    "d_majority_df = majority_df[row]\n",
    "x_train = vstack((minority_df,d_majority_df))\n",
    "y_train = np.concatenate((t_lab,y_train[row]))\n",
    "\n",
    "x_train.shape, y_train.shape,x_test.shape, y_test.shape\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize the text samples into a 2D integer tensor and use different datasets as training set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use df_training as training set and df_testing as test set\n",
    "trainingtext_with_o = df_training.drop('label',axis=1)\n",
    "traininglabel_with_o = df_training.label.values\n",
    "#print (trainingtext_with_o)\n",
    "#print(traininglabel_with_o)\n",
    "\n",
    "v = DictVectorizer(sparse=True)\n",
    "x_train = v.fit_transform(trainingtext_with_o.to_dict('records'))\n",
    "#print(trainingtext_with_o)\n",
    "y_train = traininglabel_with_o\n",
    "\n",
    "classes = np.unique(traininglabel_with_o)\n",
    "classes = classes.tolist()\n",
    "#print(classes)\n",
    "\n",
    "testingtext_with_o = df_testing.drop('label',axis=1)\n",
    "#print(testingtext_with_o)\n",
    "x_test = v.transform(testingtext_with_o.to_dict('records'))\n",
    "#print(x_test)\n",
    "y_test = df_testing.label.values\n",
    "#print(y_test)\n",
    "\n",
    "x_train.shape, y_train.shape,x_test.shape, y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CAD', 'DIABETES', 'FAMILY_HIST', 'HYPERLIPIDEMIA', 'HYPERTENSION',\n",
       "       'MEDICATION', 'O', 'OBESE', 'SMOKER'], dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_classes = classes.copy()\n",
    "#new_classes.pop() #remove the last element 'O' from the list\n",
    "new_classes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below you can train in different classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1-- Epoch 1\n",
      "\n",
      "-- Epoch 1\n",
      "-- Epoch 1\n",
      "-- Epoch 1\n",
      "-- Epoch 1\n",
      "-- Epoch 1\n",
      "-- Epoch 1\n",
      "-- Epoch 1\n",
      "Norm: 31.29, NNZs: 979, Bias: -0.150000, T: 489694, Avg. loss: 0.008481\n",
      "Total training time: 0.28 seconds.\n",
      "Norm: 12.57, NNZs: 158, Bias: -0.080000, T: 489694, Avg. loss: 0.000502\n",
      "Total training time: 0.37 seconds.\n",
      "Norm: 19.87, NNZs: 395, Bias: -0.070000, T: 489694, Avg. loss: 0.003240\n",
      "Total training time: 0.29 seconds.\n",
      "Norm: 67.58, NNZs: 4567, Bias: 0.010000, T: 489694, Avg. loss: 0.022582\n",
      "Total training time: 0.31 seconds.\n",
      "Norm: 7.07, NNZs: 50, Bias: -0.080000, T: 489694, Avg. loss: 0.000449\n",
      "Total training time: 0.31 seconds.\n",
      "Norm: 9.17, NNZs: 84, Bias: -0.040000, T: 489694, Avg. loss: 0.000246\n",
      "Total training time: 0.32 seconds.\n",
      "Norm: 30.66, NNZs: 940, Bias: -0.020000, T: 489694, Avg. loss: 0.002235\n",
      "Total training time: 0.34 seconds.\n",
      "Norm: 37.46, NNZs: 1403, Bias: -0.010000, T: 489694, Avg. loss: 0.005298\n",
      "Total training time: 0.34 seconds.\n",
      "Norm: 24.76, NNZs: 613, Bias: -0.050000, T: 489694, Avg. loss: 0.002597\n",
      "Total training time: 0.36 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    0.4s remaining:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   9 | elapsed:    0.4s remaining:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   9 | elapsed:    0.4s remaining:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   9 | elapsed:    0.4s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    0.4s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of   9 | elapsed:    0.5s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    0.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'O' 'O' ... 'O' 'O' 'O']\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'to_csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [39], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m y_pred\u001b[39m=\u001b[39mper\u001b[39m.\u001b[39mpredict(x_test)\n\u001b[0;32m      4\u001b[0m \u001b[39mprint\u001b[39m(y_pred)\n\u001b[1;32m----> 5\u001b[0m y_pred\u001b[39m.\u001b[39;49mto_csv(\u001b[39m'\u001b[39m\u001b[39m../BERT/per.txt\u001b[39m\u001b[39m'\u001b[39m,index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'to_csv'"
     ]
    }
   ],
   "source": [
    "per = Perceptron(verbose=10, n_jobs=-1, max_iter=5) #this is the perceptron model\n",
    "per.partial_fit(x_train, y_train,classes=classes)\n",
    "y_pred=per.predict(x_test)\n",
    "print(y_pred)\n",
    "y_pred.to_csv('../BERT/per.txt',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../BERT/pred.txt', 'w') as f:\n",
    "    for i in range(len(y_pred)):\n",
    "        f.write(df_testing['text'][i] + ' ' + y_test[i] + ' ' + y_pred[i] + '\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#support vector machine\n",
    "svm = SGDClassifier(alpha=.00001, max_iter=100,penalty=\"elasticnet\")\n",
    "svm.partial_fit(x_train, y_train,classes=new_classes)\n",
    "\n",
    "print (classification_report(y_pred=svm.predict(x_test), y_true=y_test, labels=new_classes))\n",
    "#labels=classes means the performance evaluation is based on all the labels \n",
    "#labels=new_classes means the performance evaluation is based on all the labels except 'O'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#naive bayes\n",
    "nb = MultinomialNB(alpha=.0005)\n",
    "nb.partial_fit(x_train, y_train,classes=classes)\n",
    "\n",
    "print (classification_report(y_pred=nb.predict(x_test), y_true=y_test, labels=new_classes))\n",
    "#labels=classes means the performance evaluation is based on all the labels \n",
    "#labels=new_classes means the performance evaluation is based on all the labels except 'O'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random forest\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=20,random_state=553)\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "print (classification_report(y_pred=rf.predict(x_test), y_true=y_test, labels=classes))\n",
    "#labels=classes means the performance evaluation is based on all the labels \n",
    "#labels=new_classes means the performance evaluation is based on all the labels except 'O'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(x_train, y_train)\n",
    "\n",
    "print (classification_report(y_pred=lr.predict(x_test), y_true=y_test, labels=new_classes))\n",
    "#labels=classes means the performance evaluation is based on all the labels \n",
    "#labels=new_classes means the performance evaluation is based on all the labels except 'O'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training without o———choose one of the following training and testing method to run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize the text samples into a 2D integer tensor and split the trainingdata into a training set and a validation set for primary results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingtext_without_o = df_training_withouto.drop('label',axis=1) #drop the label column\n",
    "#print (trainingtext_without_o)\n",
    "\n",
    "v = DictVectorizer(sparse=True)\n",
    "trainingtext_without_o = v.fit_transform(trainingtext_without_o.to_dict('records')) \n",
    "#print(trainingtext_without_o)\n",
    "traininglabel_without_o = df_training_withouto.label.values\n",
    "\n",
    "classes_without_o = np.unique(traininglabel_without_o)\n",
    "classes_without_o = classes_without_o.tolist()\n",
    "\n",
    "x_without_o_train, x_without_o_test, y_without_o_train, y_without_o_test = train_test_split(trainingtext_without_o, traininglabel_without_o, test_size = 0.1, random_state=0)\n",
    "x_without_o_train.shape, y_without_o_train.shape,x_without_o_test.shape, y_without_o_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize the text samples into a 2D integer tensor and use different datasets as training set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainingtext_without_o = df_training_withouto.drop('label',axis=1)\n",
    "traininglabel_without_o = df_training_withouto.label.values\n",
    "\n",
    "v = DictVectorizer(sparse=True)\n",
    "x_without_o_train = v.fit_transform(trainingtext_without_o.to_dict('records'))\n",
    "y_without_o_train = traininglabel_without_o\n",
    "\n",
    "classes_without_o = np.unique(traininglabel_without_o)\n",
    "classes_without_o = classes_without_o.tolist()\n",
    "\n",
    "\n",
    "testingtext_without_o = df_testing.drop('label',axis=1)\n",
    "\n",
    "x_without_o_test = v.transform(testingtext_without_o.to_dict('records'))\n",
    "y_without_o_test = df_testing.label.values\n",
    "\n",
    "\n",
    "x_without_o_train.shape, y_without_o_train.shape,x_without_o_test.shape, y_without_o_test.shape\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below you can train in different classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perceptron\n",
    "per_no = Perceptron(verbose=10, n_jobs=-1, max_iter=20) #this is the perceptron model\n",
    "per_no.partial_fit(x_without_o_train, y_without_o_train,classes=classes_without_o)\n",
    "\n",
    "print (classification_report(y_pred=per_no.predict(x_without_o_test), y_true=y_without_o_test, labels=classes_without_o))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#support vector machine\n",
    "svm_no = SGDClassifier(alpha=.00001, max_iter=100,penalty=\"elasticnet\")\n",
    "svm_no.partial_fit(x_without_o_train, y_without_o_train,classes=classes_without_o)\n",
    "\n",
    "print (classification_report(y_pred=svm_no.predict(x_without_o_test), y_true=y_without_o_test, labels=classes_without_o))\n",
    "\n",
    "print(precision_score(y_pred=svm_no.predict(x_without_o_test), y_true=y_without_o_test, labels=classes_without_o, average='micro'))\n",
    "print(recall_score(y_pred=svm_no.predict(x_without_o_test), y_true=y_without_o_test, labels=classes_without_o, average='micro'))\n",
    "print(f1_score(y_pred=svm_no.predict(x_without_o_test), y_true=y_without_o_test, labels=classes_without_o, average='micro'))\n",
    "print(precision_score(y_pred=svm_no.predict(x_without_o_test), y_true=y_without_o_test, labels=classes_without_o, average='macro'))\n",
    "print(recall_score(y_pred=svm_no.predict(x_without_o_test), y_true=y_without_o_test, labels=classes_without_o, average='macro'))\n",
    "print(f1_score(y_pred=svm_no.predict(x_without_o_test), y_true=y_without_o_test, labels=classes_without_o, average='macro'))\n",
    "print(precision_score(y_pred=svm_no.predict(x_without_o_test), y_true=y_without_o_test, labels=classes_without_o, average='weighted'))\n",
    "print(recall_score(y_pred=svm_no.predict(x_without_o_test), y_true=y_without_o_test, labels=classes_without_o, average='weighted'))\n",
    "print(f1_score(y_pred=svm_no.predict(x_without_o_test), y_true=y_without_o_test, labels=classes_without_o, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#naive bayes\n",
    "nb_no = MultinomialNB(alpha=0.01)\n",
    "nb_no.partial_fit(x_without_o_train, y_without_o_train,classes=classes_without_o)\n",
    "\n",
    "#打印分类报告，并保留四位小数\n",
    "print (classification_report(y_pred=nb_no.predict(x_without_o_test), y_true=y_without_o_test, labels=classes_without_o))\n",
    "\n",
    "print(precision_score(y_pred=nb_no.predict(x_without_o_test), y_true=y_without_o_test, labels=classes_without_o, average='micro'))\n",
    "print(recall_score(y_pred=nb_no.predict(x_without_o_test), y_true=y_without_o_test, labels=classes_without_o, average='micro'))\n",
    "print(f1_score(y_pred=nb_no.predict(x_without_o_test), y_true=y_without_o_test, labels=classes_without_o, average='micro'))\n",
    "print(precision_score(y_pred=nb_no.predict(x_without_o_test), y_true=y_without_o_test, labels=classes_without_o, average='macro'))\n",
    "print(recall_score(y_pred=nb_no.predict(x_without_o_test), y_true=y_without_o_test, labels=classes_without_o, average='macro'))\n",
    "print(f1_score(y_pred=nb_no.predict(x_without_o_test), y_true=y_without_o_test, labels=classes_without_o, average='macro'))\n",
    "print(precision_score(y_pred=nb_no.predict(x_without_o_test), y_true=y_without_o_test, labels=classes_without_o, average='weighted'))\n",
    "print(recall_score(y_pred=nb_no.predict(x_without_o_test), y_true=y_without_o_test, labels=classes_without_o, average='weighted'))\n",
    "print(f1_score(y_pred=nb_no.predict(x_without_o_test), y_true=y_without_o_test, labels=classes_without_o, average='weighted'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random forest\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=30,random_state=533)\n",
    "rf.fit(x_without_o_train, y_without_o_train)\n",
    "\n",
    "print (classification_report(y_pred=rf.predict(x_without_o_test), y_true=y_without_o_test, labels=classes_without_o))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(x_without_o_train, y_without_o_train)\n",
    "\n",
    "print (classification_report(y_pred=lr.predict(x_without_o_test), y_true=y_without_o_test, labels=classes_without_o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decision tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(x_without_o_train, y_without_o_train)\n",
    "\n",
    "print (classification_report(y_pred=dt.predict(x_without_o_test), y_true=y_without_o_test, labels=classes_without_o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#knn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(x_without_o_train, y_without_o_train)\n",
    "\n",
    "print (classification_report(y_pred=knn.predict(x_without_o_test), y_true=y_without_o_test, labels=classes_without_o))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stanford NER tagger result calculation\n",
    "## just for calculating the accuracy of stanford NER tagger, not for training and testing of traditional machine learning classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_test当中除去o的数目\n",
    "total = y_test[y_test != 'O']\n",
    "print(len(total))\n",
    "\n",
    "TP = 2690\n",
    "FP = 1810\n",
    "FN = 3209\n",
    "TN = total.size - TP - FP - FN\n",
    "print(TP, FP, FN, TN)\n",
    "\n",
    "#calculate the accuracy\n",
    "accuracy = (TP + TN) / (TP + FP + FN + TN)\n",
    "print(accuracy)\n",
    "\n",
    "#calculate the precision\n",
    "precision = TP / (TP + FP)\n",
    "print(precision)\n",
    "\n",
    "#calculate the recall\n",
    "recall = TP / (TP + FN)\n",
    "print(recall)\n",
    "\n",
    "#calculate the F1 score\n",
    "F1 = 2 * precision * recall / (precision + recall)\n",
    "print(F1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read result.txt\n",
    "path = 'E:/JHU/课程/datadesign/NLP/machine_learning/stanford-ner-4.2.0/stanford-ner-2020-11-17/test'\n",
    "\n",
    "data = pd.read_csv(path + '/result_M40_N0_chris2useLC.txt', sep='\\t', header=None, names=['Entity', 'Percision', 'Recall', 'F1', 'TP', 'FP', 'FN'])\n",
    "#Drop the first row\n",
    "data = data.drop([0])\n",
    "\n",
    "print(data)\n",
    "print('')\n",
    "\n",
    "#Drop the last row\n",
    "data = data.drop([len(data)])\n",
    "data = data.reset_index(drop=True)\n",
    "\n",
    "\n",
    "#convert the data type\n",
    "data['Percision'] = data['Percision'].astype(float)\n",
    "data['Recall'] = data['Recall'].astype(float)\n",
    "data['F1'] = data['F1'].astype(float)\n",
    "data['TP'] = data['TP'].astype(int)\n",
    "data['FP'] = data['FP'].astype(int)\n",
    "data['FN'] = data['FN'].astype(int)\n",
    "#print(data)\n",
    "\n",
    "#calculate the micro average\n",
    "TP = data['TP'].sum()\n",
    "FP = data['FP'].sum()\n",
    "FN = data['FN'].sum()\n",
    "micro_precision = TP / (TP + FP)\n",
    "micro_recall = TP / (TP + FN)\n",
    "micro_F1 = 2 * micro_precision * micro_recall / (micro_precision + micro_recall)\n",
    "\n",
    "#calculate the macro average\n",
    "macro_precision = data['Percision'].mean()\n",
    "macro_recall = data['Recall'].mean()\n",
    "macro_F1 = data['F1'].mean()\n",
    "\n",
    "#calculate the support\n",
    "support = data['TP']\n",
    "#print(support)\n",
    "#add the support to the dataframe\n",
    "data['support'] = support\n",
    "support_proportion = support / support.sum()\n",
    "#print(support_proportion)\n",
    "\n",
    "#calculate the weighted average\n",
    "weighted_precision = (data['Percision'] * support_proportion).sum()\n",
    "weighted_recall = (data['Recall'] * support_proportion).sum()\n",
    "weighted_F1 = (data['F1'] * support_proportion).sum()\n",
    "\n",
    "\n",
    "Evalution = pd.DataFrame(columns=['Entity', 'Percision', 'Recall', 'F1', 'TP', 'FP', 'FN','support'])\n",
    "Evalution.loc[len(Evalution)] = ['micro-average', micro_precision, micro_recall, micro_F1, TP, FP, FN, support.sum()]\n",
    "Evalution.loc[len(Evalution)] = ['macro-average', macro_precision, macro_recall, macro_F1, TP, FP, FN, support.sum()]\n",
    "Evalution.loc[len(Evalution)] = ['weighted-average', weighted_precision, weighted_recall, weighted_F1, TP, FP, FN, support.sum()]\n",
    "\n",
    "\n",
    "print(data)\n",
    "print('')\n",
    "print(Evalution)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataweek2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4600a15e5b6b646e3db8b2d8ebb346444f23fb424fa93d368313be03df29f350"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

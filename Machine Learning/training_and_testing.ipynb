{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(336882, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Record</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>date:</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2067-05-03</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Narrative</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>History</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         text label\n",
       "0      Record     O\n",
       "1       date:     O\n",
       "2  2067-05-03     O\n",
       "3   Narrative     O\n",
       "4     History     O"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read txt file\n",
    "def read_txt(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        data = f.readlines()\n",
    "    return data\n",
    "\n",
    "\n",
    "traininglist1 = read_txt('../BERT/data_processed/train_1(no_BIO).txt')\n",
    "#traininglist2 = read_txt('./trainingdata2_noPHI.txt')\n",
    "#traininglist = traininglist1 + traininglist2\n",
    "#traininglist3 = read_txt('./train_withoutphi.txt')\n",
    "\n",
    "#you could pick one of the trainingset to train the model. \n",
    "#Traininglist1 is the first trainingset, traininglist2 is the second trainingset, traininglist3 is the combination.\n",
    "traininglist = traininglist1\n",
    "\n",
    "#print(list)\n",
    "for i in range(len(traininglist)):\n",
    "    traininglist[i] = traininglist[i].split()\n",
    "#print(list)\n",
    "\n",
    "trainingdataframe = pd.DataFrame(traininglist, columns=['text', 'label'])\n",
    "print(trainingdataframe.shape)\n",
    "trainingdataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42418, 9)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_training = trainingdataframe.fillna(method='ffill')\n",
    "df_training.text.nunique(), df_training.label.nunique()  #check the number of unique words and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the training data if you want to use it later\n",
    "#df_training.to_csv('E:/JHU/课程/datadesign/NLP/machine_learning/trainingdatacombine_withoutphi.txt', index=False, header=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CAD</td>\n",
       "      <td>3873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DIABETES</td>\n",
       "      <td>1571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FAMILY_HIST</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HYPERLIPIDEMIA</td>\n",
       "      <td>421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HYPERTENSION</td>\n",
       "      <td>1463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MEDICATION</td>\n",
       "      <td>4593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>O</td>\n",
       "      <td>323131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>OBESE</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SMOKER</td>\n",
       "      <td>1554</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            label  counts\n",
       "0             CAD    3873\n",
       "1        DIABETES    1571\n",
       "2     FAMILY_HIST      87\n",
       "3  HYPERLIPIDEMIA     421\n",
       "4    HYPERTENSION    1463\n",
       "5      MEDICATION    4593\n",
       "6               O  323131\n",
       "7           OBESE     189\n",
       "8          SMOKER    1554"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_training.groupby('label').size().reset_index(name='counts') #check the number of each label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CAD</td>\n",
       "      <td>3873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O</td>\n",
       "      <td>333009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  counts\n",
       "0   CAD    3873\n",
       "1     O  333009"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#delete the rows with label 'O', and generate a new dataframe without 'O' for training without 'O'\n",
    "df_training.loc[df_training.label != 'CAD',\"label\"] = 'O'\n",
    "df_training.groupby('label').size().reset_index(name='counts')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leste\\AppData\\Local\\Temp\\ipykernel_12740\\1891493014.py:13: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = minority_df.append(undersampled_majority_df, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# make two dataframes, each with only one class \n",
    "majority_df = df_training[df_training['label']==\"O\"]\n",
    "minority_df = df_training[df_training['label']==\"CAD\"]\n",
    "\n",
    "# Oversampling the minority\n",
    "undersampled_majority_df = resample(majority_df,\n",
    "                          replace=False, \n",
    "                          n_samples=2*len(minority_df), \n",
    "                          random_state=123)\n",
    "\n",
    "df = minority_df.append(undersampled_majority_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('label').size().reset_index(name='counts')\n",
    "df_training = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read txt file\n",
    "testinglist = read_txt('./test_withoutphi.txt')\n",
    "#print(list)\n",
    "\n",
    "for i in range(len(testinglist)):\n",
    "    testinglist[i] = testinglist[i].split()\n",
    "#print(list)\n",
    "\n",
    "testingdataframe = pd.DataFrame(testinglist,columns=['text','label'])\n",
    "print(testingdataframe.shape)\n",
    "testingdataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_testing = testingdataframe.fillna(method='ffill')\n",
    "df_testing.text.nunique(), df_testing.label.nunique() #check the number of unique words and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_testing.groupby('label').size().reset_index(name='counts') #check the number of each label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with o class———choose one of the following training and testing method to run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize the text samples into a 2D integer tensor and split the trainingdata into a training set and a validation set for primary results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8133, 4545), (8133,), (3486, 4545), (3486,))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingtext_with_o = df_training.drop('label',axis=1)  #drop the label column\n",
    "traininglabel_with_o = df_training.label.values #get the label column\n",
    "#print (trainingtext_with_o)\n",
    "#print(traininglabel_with_o)\n",
    "\n",
    "v = DictVectorizer(sparse=True) #sparse=True means the output is a sparse matrix\n",
    "trainingtext_with_o = v.fit_transform(trainingtext_with_o.to_dict('records')) #to_dict('records') means the output is a list of dictionaries\n",
    "#print(trainingtext_with_o)\n",
    "\n",
    "classes = np.unique(traininglabel_with_o) #get the unique labels as classes for performance evaluation\n",
    "classes = classes.tolist() #convert the numpy array to list\n",
    "#print(classes)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(trainingtext_with_o, traininglabel_with_o, test_size = 0.3, random_state=0) \n",
    "\n",
    "x_train.shape, y_train.shape,x_test.shape, y_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize the text samples into a 2D integer tensor and use different datasets as training set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use df_training as training set and df_testing as test set\n",
    "trainingtext_with_o = df_training.drop('label',axis=1)\n",
    "traininglabel_with_o = df_training.label.values\n",
    "#print (trainingtext_with_o)\n",
    "#print(traininglabel_with_o)\n",
    "\n",
    "v = DictVectorizer(sparse=True)\n",
    "x_train = v.fit_transform(trainingtext_with_o.to_dict('records'))\n",
    "#print(trainingtext_with_o)\n",
    "y_train = traininglabel_with_o\n",
    "\n",
    "classes = np.unique(traininglabel_with_o)\n",
    "classes = classes.tolist()\n",
    "#print(classes)\n",
    "\n",
    "testingtext_with_o = df_testing.drop('label',axis=1)\n",
    "#print(testingtext_with_o)\n",
    "x_test = v.transform(testingtext_with_o.to_dict('records'))\n",
    "#print(x_test)\n",
    "y_test = df_testing.label.values\n",
    "#print(y_test)\n",
    "\n",
    "x_train.shape, y_train.shape,x_test.shape, y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CAD', 'O']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_classes = classes.copy()\n",
    "#new_classes.pop(6) #remove the last element 'O' from the list\n",
    "new_classes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below you can train in different classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 35.16, NNZs: 1236, Bias: 0.020000, T: 8133, Avg. loss: 0.073158\n",
      "Total training time: 0.00 seconds.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         CAD       0.77      0.55      0.64      1138\n",
      "           O       0.81      0.92      0.86      2348\n",
      "\n",
      "    accuracy                           0.80      3486\n",
      "   macro avg       0.79      0.74      0.75      3486\n",
      "weighted avg       0.80      0.80      0.79      3486\n",
      "\n"
     ]
    }
   ],
   "source": [
    "per = Perceptron(verbose=10, n_jobs=-1, max_iter=5) #this is the perceptron model\n",
    "per.partial_fit(x_train, y_train,classes=classes)\n",
    "print (classification_report(y_pred=per.predict(x_test), y_true=y_test, labels=new_classes)) \n",
    "#labels=classes means the performance evaluation is based on all the labels \n",
    "#labels=new_classes means the performance evaluation is based on all the labels except 'O'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         CAD       0.74      0.60      0.66      1138\n",
      "           O       0.82      0.90      0.86      2348\n",
      "\n",
      "    accuracy                           0.80      3486\n",
      "   macro avg       0.78      0.75      0.76      3486\n",
      "weighted avg       0.79      0.80      0.79      3486\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#support vector machine\n",
    "svm = SGDClassifier(alpha=.00001, max_iter=100,penalty=\"elasticnet\")\n",
    "svm.partial_fit(x_train, y_train,classes=new_classes)\n",
    "\n",
    "print (classification_report(y_pred=svm.predict(x_test), y_true=y_test, labels=new_classes))\n",
    "#labels=classes means the performance evaluation is based on all the labels \n",
    "#labels=new_classes means the performance evaluation is based on all the labels except 'O'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         CAD       0.83      0.58      0.68      1138\n",
      "           O       0.82      0.94      0.88      2348\n",
      "\n",
      "    accuracy                           0.82      3486\n",
      "   macro avg       0.83      0.76      0.78      3486\n",
      "weighted avg       0.83      0.82      0.82      3486\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#naive bayes\n",
    "nb = MultinomialNB(alpha=.0005)\n",
    "nb.partial_fit(x_train, y_train,classes=classes)\n",
    "\n",
    "print (classification_report(y_pred=nb.predict(x_test), y_true=y_test, labels=new_classes))\n",
    "#labels=classes means the performance evaluation is based on all the labels \n",
    "#labels=new_classes means the performance evaluation is based on all the labels except 'O'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [21], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m#random forest\u001b[39;00m\n\u001b[0;32m      2\u001b[0m rf \u001b[39m=\u001b[39m RandomForestClassifier(n_estimators\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m, max_depth\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m,random_state\u001b[39m=\u001b[39m\u001b[39m553\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m rf\u001b[39m.\u001b[39;49mfit(x_train, y_train)\n\u001b[0;32m      5\u001b[0m \u001b[39mprint\u001b[39m (classification_report(y_pred\u001b[39m=\u001b[39mrf\u001b[39m.\u001b[39mpredict(x_test), y_true\u001b[39m=\u001b[39my_test, labels\u001b[39m=\u001b[39mclasses))\n",
      "File \u001b[1;32mc:\\Users\\Leste\\anaconda3\\envs\\dataweek2\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:450\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    439\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[0;32m    440\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[0;32m    441\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    442\u001b[0m ]\n\u001b[0;32m    444\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    445\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    446\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    447\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    448\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 450\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[0;32m    451\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[0;32m    452\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    453\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m_joblib_parallel_args(prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m    454\u001b[0m )(\n\u001b[0;32m    455\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[0;32m    456\u001b[0m         t,\n\u001b[0;32m    457\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[0;32m    458\u001b[0m         X,\n\u001b[0;32m    459\u001b[0m         y,\n\u001b[0;32m    460\u001b[0m         sample_weight,\n\u001b[0;32m    461\u001b[0m         i,\n\u001b[0;32m    462\u001b[0m         \u001b[39mlen\u001b[39;49m(trees),\n\u001b[0;32m    463\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    464\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[0;32m    465\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39;49mn_samples_bootstrap,\n\u001b[0;32m    466\u001b[0m     )\n\u001b[0;32m    467\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, t \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(trees)\n\u001b[0;32m    468\u001b[0m )\n\u001b[0;32m    470\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    471\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mc:\\Users\\Leste\\anaconda3\\envs\\dataweek2\\lib\\site-packages\\joblib\\parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1044\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1046\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1047\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1050\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1051\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1052\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Leste\\anaconda3\\envs\\dataweek2\\lib\\site-packages\\joblib\\parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    860\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 861\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    862\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Leste\\anaconda3\\envs\\dataweek2\\lib\\site-packages\\joblib\\parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    778\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 779\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    780\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    781\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    782\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    783\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\Leste\\anaconda3\\envs\\dataweek2\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\Leste\\anaconda3\\envs\\dataweek2\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    570\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 572\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\Leste\\anaconda3\\envs\\dataweek2\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\Leste\\anaconda3\\envs\\dataweek2\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\Leste\\anaconda3\\envs\\dataweek2\\lib\\site-packages\\sklearn\\utils\\fixes.py:216\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    215\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[1;32m--> 216\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Leste\\anaconda3\\envs\\dataweek2\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:185\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    182\u001b[0m     \u001b[39melif\u001b[39;00m class_weight \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbalanced_subsample\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    183\u001b[0m         curr_sample_weight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m compute_sample_weight(\u001b[39m\"\u001b[39m\u001b[39mbalanced\u001b[39m\u001b[39m\"\u001b[39m, y, indices\u001b[39m=\u001b[39mindices)\n\u001b[1;32m--> 185\u001b[0m     tree\u001b[39m.\u001b[39;49mfit(X, y, sample_weight\u001b[39m=\u001b[39;49mcurr_sample_weight, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    186\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    187\u001b[0m     tree\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39msample_weight, check_input\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Leste\\anaconda3\\envs\\dataweek2\\lib\\site-packages\\sklearn\\tree\\_classes.py:937\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    899\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\n\u001b[0;32m    900\u001b[0m     \u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, X_idx_sorted\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdeprecated\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    901\u001b[0m ):\n\u001b[0;32m    902\u001b[0m     \u001b[39m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    903\u001b[0m \n\u001b[0;32m    904\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    934\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    935\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 937\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m    938\u001b[0m         X,\n\u001b[0;32m    939\u001b[0m         y,\n\u001b[0;32m    940\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m    941\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[0;32m    942\u001b[0m         X_idx_sorted\u001b[39m=\u001b[39;49mX_idx_sorted,\n\u001b[0;32m    943\u001b[0m     )\n\u001b[0;32m    944\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Leste\\anaconda3\\envs\\dataweek2\\lib\\site-packages\\sklearn\\tree\\_classes.py:420\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    409\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    410\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    411\u001b[0m         splitter,\n\u001b[0;32m    412\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    417\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    418\u001b[0m     )\n\u001b[1;32m--> 420\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight)\n\u001b[0;32m    422\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[0;32m    423\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#random forest\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=20,random_state=553)\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "print (classification_report(y_pred=rf.predict(x_test), y_true=y_test, labels=classes))\n",
    "#labels=classes means the performance evaluation is based on all the labels \n",
    "#labels=new_classes means the performance evaluation is based on all the labels except 'O'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(x_train, y_train)\n",
    "\n",
    "print (classification_report(y_pred=lr.predict(x_test), y_true=y_test, labels=new_classes))\n",
    "#labels=classes means the performance evaluation is based on all the labels \n",
    "#labels=new_classes means the performance evaluation is based on all the labels except 'O'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training without o———choose one of the following training and testing method to run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize the text samples into a 2D integer tensor and split the trainingdata into a training set and a validation set for primary results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingtext_without_o = df_training_withouto.drop('label',axis=1) #drop the label column\n",
    "#print (trainingtext_without_o)\n",
    "\n",
    "v = DictVectorizer(sparse=True)\n",
    "trainingtext_without_o = v.fit_transform(trainingtext_without_o.to_dict('records')) \n",
    "#print(trainingtext_without_o)\n",
    "traininglabel_without_o = df_training_withouto.label.values\n",
    "\n",
    "classes_without_o = np.unique(traininglabel_without_o)\n",
    "classes_without_o = classes_without_o.tolist()\n",
    "\n",
    "x_without_o_train, x_without_o_test, y_without_o_train, y_without_o_test = train_test_split(trainingtext_without_o, traininglabel_without_o, test_size = 0.1, random_state=0)\n",
    "x_without_o_train.shape, y_without_o_train.shape,x_without_o_test.shape, y_without_o_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize the text samples into a 2D integer tensor and use different datasets as training set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainingtext_without_o = df_training_withouto.drop('label',axis=1)\n",
    "traininglabel_without_o = df_training_withouto.label.values\n",
    "\n",
    "v = DictVectorizer(sparse=True)\n",
    "x_without_o_train = v.fit_transform(trainingtext_without_o.to_dict('records'))\n",
    "y_without_o_train = traininglabel_without_o\n",
    "\n",
    "classes_without_o = np.unique(traininglabel_without_o)\n",
    "classes_without_o = classes_without_o.tolist()\n",
    "\n",
    "\n",
    "testingtext_without_o = df_testing.drop('label',axis=1)\n",
    "\n",
    "x_without_o_test = v.transform(testingtext_without_o.to_dict('records'))\n",
    "y_without_o_test = df_testing.label.values\n",
    "\n",
    "\n",
    "x_without_o_train.shape, y_without_o_train.shape,x_without_o_test.shape, y_without_o_test.shape\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below you can train in different classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perceptron\n",
    "per_no = Perceptron(verbose=10, n_jobs=-1, max_iter=20) #this is the perceptron model\n",
    "per_no.partial_fit(x_without_o_train, y_without_o_train,classes=classes_without_o)\n",
    "\n",
    "print (classification_report(y_pred=per_no.predict(x_without_o_test), y_true=y_without_o_test, labels=classes_without_o))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#support vector machine\n",
    "svm_no = SGDClassifier(alpha=.00001, max_iter=100,penalty=\"elasticnet\")\n",
    "svm_no.partial_fit(x_without_o_train, y_without_o_train,classes=classes_without_o)\n",
    "\n",
    "print (classification_report(y_pred=svm_no.predict(x_without_o_test), y_true=y_without_o_test, labels=classes_without_o))\n",
    "\n",
    "print(precision_score(y_pred=svm_no.predict(x_without_o_test), y_true=y_without_o_test, labels=classes_without_o, average='micro'))\n",
    "print(recall_score(y_pred=svm_no.predict(x_without_o_test), y_true=y_without_o_test, labels=classes_without_o, average='micro'))\n",
    "print(f1_score(y_pred=svm_no.predict(x_without_o_test), y_true=y_without_o_test, labels=classes_without_o, average='micro'))\n",
    "print(precision_score(y_pred=svm_no.predict(x_without_o_test), y_true=y_without_o_test, labels=classes_without_o, average='macro'))\n",
    "print(recall_score(y_pred=svm_no.predict(x_without_o_test), y_true=y_without_o_test, labels=classes_without_o, average='macro'))\n",
    "print(f1_score(y_pred=svm_no.predict(x_without_o_test), y_true=y_without_o_test, labels=classes_without_o, average='macro'))\n",
    "print(precision_score(y_pred=svm_no.predict(x_without_o_test), y_true=y_without_o_test, labels=classes_without_o, average='weighted'))\n",
    "print(recall_score(y_pred=svm_no.predict(x_without_o_test), y_true=y_without_o_test, labels=classes_without_o, average='weighted'))\n",
    "print(f1_score(y_pred=svm_no.predict(x_without_o_test), y_true=y_without_o_test, labels=classes_without_o, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#naive bayes\n",
    "nb_no = MultinomialNB(alpha=0.01)\n",
    "nb_no.partial_fit(x_without_o_train, y_without_o_train,classes=classes_without_o)\n",
    "\n",
    "#打印分类报告，并保留四位小数\n",
    "print (classification_report(y_pred=nb_no.predict(x_without_o_test), y_true=y_without_o_test, labels=classes_without_o))\n",
    "\n",
    "print(precision_score(y_pred=nb_no.predict(x_without_o_test), y_true=y_without_o_test, labels=classes_without_o, average='micro'))\n",
    "print(recall_score(y_pred=nb_no.predict(x_without_o_test), y_true=y_without_o_test, labels=classes_without_o, average='micro'))\n",
    "print(f1_score(y_pred=nb_no.predict(x_without_o_test), y_true=y_without_o_test, labels=classes_without_o, average='micro'))\n",
    "print(precision_score(y_pred=nb_no.predict(x_without_o_test), y_true=y_without_o_test, labels=classes_without_o, average='macro'))\n",
    "print(recall_score(y_pred=nb_no.predict(x_without_o_test), y_true=y_without_o_test, labels=classes_without_o, average='macro'))\n",
    "print(f1_score(y_pred=nb_no.predict(x_without_o_test), y_true=y_without_o_test, labels=classes_without_o, average='macro'))\n",
    "print(precision_score(y_pred=nb_no.predict(x_without_o_test), y_true=y_without_o_test, labels=classes_without_o, average='weighted'))\n",
    "print(recall_score(y_pred=nb_no.predict(x_without_o_test), y_true=y_without_o_test, labels=classes_without_o, average='weighted'))\n",
    "print(f1_score(y_pred=nb_no.predict(x_without_o_test), y_true=y_without_o_test, labels=classes_without_o, average='weighted'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random forest\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=30,random_state=533)\n",
    "rf.fit(x_without_o_train, y_without_o_train)\n",
    "\n",
    "print (classification_report(y_pred=rf.predict(x_without_o_test), y_true=y_without_o_test, labels=classes_without_o))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(x_without_o_train, y_without_o_train)\n",
    "\n",
    "print (classification_report(y_pred=lr.predict(x_without_o_test), y_true=y_without_o_test, labels=classes_without_o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decision tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(x_without_o_train, y_without_o_train)\n",
    "\n",
    "print (classification_report(y_pred=dt.predict(x_without_o_test), y_true=y_without_o_test, labels=classes_without_o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#knn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(x_without_o_train, y_without_o_train)\n",
    "\n",
    "print (classification_report(y_pred=knn.predict(x_without_o_test), y_true=y_without_o_test, labels=classes_without_o))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stanford NER tagger result calculation\n",
    "## just for calculating the accuracy of stanford NER tagger, not for training and testing of traditional machine learning classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_test当中除去o的数目\n",
    "total = y_test[y_test != 'O']\n",
    "print(len(total))\n",
    "\n",
    "TP = 2690\n",
    "FP = 1810\n",
    "FN = 3209\n",
    "TN = total.size - TP - FP - FN\n",
    "print(TP, FP, FN, TN)\n",
    "\n",
    "#calculate the accuracy\n",
    "accuracy = (TP + TN) / (TP + FP + FN + TN)\n",
    "print(accuracy)\n",
    "\n",
    "#calculate the precision\n",
    "precision = TP / (TP + FP)\n",
    "print(precision)\n",
    "\n",
    "#calculate the recall\n",
    "recall = TP / (TP + FN)\n",
    "print(recall)\n",
    "\n",
    "#calculate the F1 score\n",
    "F1 = 2 * precision * recall / (precision + recall)\n",
    "print(F1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read result.txt\n",
    "path = 'E:/JHU/课程/datadesign/NLP/machine_learning/stanford-ner-4.2.0/stanford-ner-2020-11-17/test'\n",
    "\n",
    "data = pd.read_csv(path + '/result_M40_N0_chris2useLC.txt', sep='\\t', header=None, names=['Entity', 'Percision', 'Recall', 'F1', 'TP', 'FP', 'FN'])\n",
    "#Drop the first row\n",
    "data = data.drop([0])\n",
    "\n",
    "print(data)\n",
    "print('')\n",
    "\n",
    "#Drop the last row\n",
    "data = data.drop([len(data)])\n",
    "data = data.reset_index(drop=True)\n",
    "\n",
    "\n",
    "#convert the data type\n",
    "data['Percision'] = data['Percision'].astype(float)\n",
    "data['Recall'] = data['Recall'].astype(float)\n",
    "data['F1'] = data['F1'].astype(float)\n",
    "data['TP'] = data['TP'].astype(int)\n",
    "data['FP'] = data['FP'].astype(int)\n",
    "data['FN'] = data['FN'].astype(int)\n",
    "#print(data)\n",
    "\n",
    "#calculate the micro average\n",
    "TP = data['TP'].sum()\n",
    "FP = data['FP'].sum()\n",
    "FN = data['FN'].sum()\n",
    "micro_precision = TP / (TP + FP)\n",
    "micro_recall = TP / (TP + FN)\n",
    "micro_F1 = 2 * micro_precision * micro_recall / (micro_precision + micro_recall)\n",
    "\n",
    "#calculate the macro average\n",
    "macro_precision = data['Percision'].mean()\n",
    "macro_recall = data['Recall'].mean()\n",
    "macro_F1 = data['F1'].mean()\n",
    "\n",
    "#calculate the support\n",
    "support = data['TP']\n",
    "#print(support)\n",
    "#add the support to the dataframe\n",
    "data['support'] = support\n",
    "support_proportion = support / support.sum()\n",
    "#print(support_proportion)\n",
    "\n",
    "#calculate the weighted average\n",
    "weighted_precision = (data['Percision'] * support_proportion).sum()\n",
    "weighted_recall = (data['Recall'] * support_proportion).sum()\n",
    "weighted_F1 = (data['F1'] * support_proportion).sum()\n",
    "\n",
    "\n",
    "Evalution = pd.DataFrame(columns=['Entity', 'Percision', 'Recall', 'F1', 'TP', 'FP', 'FN','support'])\n",
    "Evalution.loc[len(Evalution)] = ['micro-average', micro_precision, micro_recall, micro_F1, TP, FP, FN, support.sum()]\n",
    "Evalution.loc[len(Evalution)] = ['macro-average', macro_precision, macro_recall, macro_F1, TP, FP, FN, support.sum()]\n",
    "Evalution.loc[len(Evalution)] = ['weighted-average', weighted_precision, weighted_recall, weighted_F1, TP, FP, FN, support.sum()]\n",
    "\n",
    "\n",
    "print(data)\n",
    "print('')\n",
    "print(Evalution)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataweek2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4600a15e5b6b646e3db8b2d8ebb346444f23fb424fa93d368313be03df29f350"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
